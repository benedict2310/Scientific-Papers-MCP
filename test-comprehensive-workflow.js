#!/usr/bin/env node

/**
 * Comprehensive MCP Server Test: Multi-Source Research Workflow
 * 
 * This test simulates a challenging research scenario that exercises:
 * - All 6 data sources (arXiv, OpenAlex, PMC, Europe PMC, bioRxiv, CORE)
 * - Multiple tool combinations (search, fetch_latest, fetch_content, fetch_pdf_content)
 * - PDF extraction fallback scenarios
 * - Large PDF handling with confirmation
 * - Error handling and graceful degradation
 * 
 * Research Question: "Neural network quantization for edge computing"
 */

import { RateLimiter } from './dist/core/rate-limiter.js';
import { listCategories } from './dist/tools/list-categories.js';
import { searchPapers } from './dist/tools/search-papers.js';
import { fetchLatest } from './dist/tools/fetch-latest.js';
import { fetchContent } from './dist/tools/fetch-content.js';
import { fetchPdfContent } from './dist/tools/fetch-pdf-content.js';
import { logInfo } from './dist/core/logger.js';

// Test configuration
const TEST_CONFIG = {
  research_topic: "neural network quantization",
  search_query: "neural network quantization edge computing",
  max_papers_per_source: 3,
  test_timeout: 300000, // 5 minutes
  large_pdf_threshold: 10 // MB
};

// Global test state
let testResults = {
  sources_tested: 0,
  tools_tested: 0,
  pdfs_extracted: 0,
  html_fallbacks: 0,
  pdf_fallbacks: 0,
  errors_handled: 0,
  total_papers: 0,
  total_text_length: 0,
  performance_metrics: {}
};

// Rate limiter instance
const rateLimiter = new RateLimiter();

// Utility functions
function printHeader(title) {
  console.log(`\n${'='.repeat(80)}`);
  console.log(`ðŸ”¬ ${title}`);
  console.log(`${'='.repeat(80)}`);
}

function printSection(title) {
  console.log(`\n${'â”€'.repeat(60)}`);
  console.log(`ðŸ“‹ ${title}`);
  console.log(`${'â”€'.repeat(60)}`);
}

function printResult(emoji, message, data = {}) {
  console.log(`${emoji} ${message}`);
  if (Object.keys(data).length > 0) {
    console.log(`   ðŸ“Š ${JSON.stringify(data)}`);
  }
}

function measureTime(startTime) {
  return ((Date.now() - startTime) / 1000).toFixed(2);
}

// Test Phase 1: Discovery Phase - Search across sources
async function testDiscoveryPhase() {
  printSection("Phase 1: Discovery - Search Across Sources");
  
  const searchSources = [
    { source: 'arxiv', field: 'all' },
    { source: 'openalex', field: 'title' },
    { source: 'europepmc', field: 'abstract' },
    { source: 'core', field: 'fulltext' }
  ];

  const discoveryResults = {};

  for (const { source, field } of searchSources) {
    const startTime = Date.now();
    
    try {
      printResult('ðŸ”', `Searching ${source} in ${field} field...`);
      
      const result = await searchPapers({
        source,
        query: TEST_CONFIG.search_query,
        field,
        count: TEST_CONFIG.max_papers_per_source,
        sortBy: 'relevance'
      }, rateLimiter);

      const duration = measureTime(startTime);
      discoveryResults[source] = {
        papers_found: result.content.length,
        duration_seconds: duration,
        has_pdfs: result.content.filter(p => p.pdf_url).length
      };

      printResult('âœ…', `Found ${result.content.length} papers in ${duration}s`, discoveryResults[source]);
      
      testResults.sources_tested++;
      testResults.total_papers += result.content.length;
      
    } catch (error) {
      const duration = measureTime(startTime);
      discoveryResults[source] = { error: error.message, duration_seconds: duration };
      printResult('âŒ', `Search failed for ${source}: ${error.message}`);
      testResults.errors_handled++;
    }
  }

  testResults.tools_tested++;
  testResults.performance_metrics.discovery = discoveryResults;
  return discoveryResults;
}

// Test Phase 2: Comparison Phase - Latest papers from different sources
async function testComparisonPhase() {
  printSection("Phase 2: Comparison - Latest Papers from Different Sources");
  
  const latestSources = [
    { source: 'arxiv', category: 'cs.AI' },
    { source: 'openalex', category: 'C41008148' }, // Computer Science
    { source: 'biorxiv', category: 'biorxiv:bioinformatics' },
    { source: 'core', category: 'computer_science' }
  ];

  const comparisonResults = {};
  const candidatePapers = [];

  for (const { source, category } of latestSources) {
    const startTime = Date.now();
    
    try {
      printResult('ðŸ“°', `Fetching latest papers from ${source}...`);
      
      const result = await fetchLatest({
        source,
        category,
        count: TEST_CONFIG.max_papers_per_source
      }, rateLimiter);

      const duration = measureTime(startTime);
      comparisonResults[source] = {
        papers_found: result.content.length,
        duration_seconds: duration,
        has_pdfs: result.content.filter(p => p.pdf_url).length,
        avg_recency: result.content.length > 0 ? 
          result.content.reduce((sum, p) => sum + (new Date() - new Date(p.date)) / (1000 * 60 * 60 * 24), 0) / result.content.length : 0
      };

      printResult('âœ…', `Retrieved ${result.content.length} latest papers in ${duration}s`, comparisonResults[source]);
      
      // Add promising candidates for deep dive
      candidatePapers.push(...result.content.slice(0, 1).map(p => ({ ...p, source })));
      
    } catch (error) {
      const duration = measureTime(startTime);
      comparisonResults[source] = { error: error.message, duration_seconds: duration };
      printResult('âŒ', `Latest fetch failed for ${source}: ${error.message}`);
      testResults.errors_handled++;
    }
  }

  testResults.tools_tested++;
  testResults.performance_metrics.comparison = comparisonResults;
  return candidatePapers;
}

// Test Phase 3: Deep Dive Phase - Full content extraction with PDF fallback
async function testDeepDivePhase(candidatePapers) {
  printSection("Phase 3: Deep Dive - Full Content Extraction with PDF Fallback");
  
  const deepDiveResults = {};
  const extractedPapers = [];

  for (const paper of candidatePapers) {
    const startTime = Date.now();
    
    try {
      printResult('ðŸ“–', `Extracting full content for: ${paper.title.substring(0, 50)}...`);
      
      const result = await fetchContent({
        source: paper.source,
        id: paper.id
      }, rateLimiter);

      const duration = measureTime(startTime);
      const textLength = result.content.text.length;
      const extractionMethod = textLength > 0 ? 
        (result.content.text.includes('PDF') ? 'PDF fallback' : 'HTML primary') : 'Failed';

      deepDiveResults[paper.id] = {
        source: paper.source,
        title: paper.title.substring(0, 50),
        text_length: textLength,
        extraction_method: extractionMethod,
        duration_seconds: duration,
        has_pdf_url: !!paper.pdf_url,
        truncated: result.content.textTruncated,
        extraction_failed: result.content.textExtractionFailed
      };

      if (textLength > 0) {
        printResult('âœ…', `Extracted ${textLength} characters in ${duration}s`, {
          method: extractionMethod,
          truncated: result.content.textTruncated
        });
        
        testResults.total_text_length += textLength;
        if (extractionMethod === 'PDF fallback') {
          testResults.pdf_fallbacks++;
        } else {
          testResults.html_fallbacks++;
        }
      } else {
        printResult('âš ï¸', `No text extracted for ${paper.source}:${paper.id}`);
      }

      extractedPapers.push({ ...paper, content: result.content });
      
    } catch (error) {
      const duration = measureTime(startTime);
      deepDiveResults[paper.id] = { 
        error: error.message, 
        duration_seconds: duration,
        source: paper.source 
      };
      printResult('âŒ', `Content extraction failed: ${error.message}`);
      testResults.errors_handled++;
    }
  }

  testResults.tools_tested++;
  testResults.performance_metrics.deep_dive = deepDiveResults;
  return extractedPapers;
}

// Test Phase 4: Validation Phase - Large PDFs and edge cases
async function testValidationPhase() {
  printSection("Phase 4: Validation - Large PDFs and Edge Cases");
  
  const validationResults = {};
  
  // Test 1: Direct PDF extraction with size checking
  const testPdfs = [
    {
      name: "arXiv_medium",
      url: "http://arxiv.org/pdf/2507.11539v1.pdf",
      expected_size: "~9MB"
    },
    {
      name: "arXiv_larger", 
      url: "http://arxiv.org/pdf/2507.11538v1.pdf",
      expected_size: "~6MB"
    }
  ];

  for (const { name, url, expected_size } of testPdfs) {
    const startTime = Date.now();
    
    try {
      printResult('ðŸ“„', `Testing direct PDF extraction: ${name} (${expected_size})...`);
      
      const result = await fetchPdfContent.execute({
        url,
        maxSizeMB: 25,
        maxPages: 100,
        timeout: 120,
        confirmLargeFiles: false // Disable confirmation for testing
      });

      const duration = measureTime(startTime);
      
      if (result.success) {
        validationResults[name] = {
          success: true,
          text_length: result.text.length,
          page_count: result.metadata.pageCount,
          pdf_size_mb: result.metadata.sizeMB,
          duration_seconds: duration,
          truncated: result.metadata.textTruncated,
          context_warning: result.metadata.contextWarning
        };
        
        printResult('âœ…', `PDF extracted successfully in ${duration}s`, {
          pages: result.metadata.pageCount,
          size: `${result.metadata.sizeMB.toFixed(1)}MB`,
          chars: result.text.length
        });
        
        testResults.pdfs_extracted++;
        testResults.total_text_length += result.text.length;
        
      } else {
        validationResults[name] = {
          success: false,
          error: result.error,
          duration_seconds: duration,
          cancelled: result.cancelled
        };
        
        printResult('âŒ', `PDF extraction failed: ${result.error}`);
        testResults.errors_handled++;
      }
      
    } catch (error) {
      const duration = measureTime(startTime);
      validationResults[name] = { 
        error: error.message, 
        duration_seconds: duration 
      };
      printResult('âŒ', `PDF test failed: ${error.message}`);
      testResults.errors_handled++;
    }
  }

  // Test 2: Error handling scenarios
  printResult('ðŸ§ª', "Testing error handling scenarios...");
  
  const errorTests = [
    {
      name: "non_existent_pdf",
      url: "http://arxiv.org/pdf/9999.99999v1.pdf",
      expected_error: "404 or similar"
    },
    {
      name: "invalid_url",
      url: "not-a-valid-url",
      expected_error: "URL validation error"
    }
  ];

  for (const { name, url, expected_error } of errorTests) {
    try {
      const result = await fetchPdfContent.execute({
        url,
        maxSizeMB: 10,
        maxPages: 50,
        timeout: 30,
        confirmLargeFiles: false
      });
      
      if (!result.success) {
        validationResults[name] = {
          error_handled: true,
          error_message: result.error,
          expected: expected_error
        };
        printResult('âœ…', `Error handled correctly: ${name}`);
        testResults.errors_handled++;
      } else {
        printResult('âš ï¸', `Expected error but got success: ${name}`);
      }
      
    } catch (error) {
      validationResults[name] = {
        error_handled: true,
        error_message: error.message,
        expected: expected_error
      };
      printResult('âœ…', `Error handled correctly: ${name}`);
      testResults.errors_handled++;
    }
  }

  testResults.tools_tested++;
  testResults.performance_metrics.validation = validationResults;
  return validationResults;
}

// Generate comprehensive test report
function generateTestReport() {
  printHeader("COMPREHENSIVE TEST REPORT");
  
  console.log(`\nðŸ“Š OVERALL STATISTICS:`);
  console.log(`   Sources Tested: ${testResults.sources_tested}/6`);
  console.log(`   Tools Tested: ${testResults.tools_tested}/4`);
  console.log(`   Total Papers Processed: ${testResults.total_papers}`);
  console.log(`   PDFs Extracted: ${testResults.pdfs_extracted}`);
  console.log(`   HTML Extractions: ${testResults.html_fallbacks}`);
  console.log(`   PDF Fallbacks: ${testResults.pdf_fallbacks}`);
  console.log(`   Errors Handled: ${testResults.errors_handled}`);
  console.log(`   Total Text Extracted: ${(testResults.total_text_length / 1000).toFixed(1)}K characters`);
  
  console.log(`\nâ±ï¸ PERFORMANCE METRICS:`);
  for (const [phase, metrics] of Object.entries(testResults.performance_metrics)) {
    console.log(`   ${phase.toUpperCase()}:`);
    for (const [source, data] of Object.entries(metrics)) {
      if (data.duration_seconds) {
        console.log(`     ${source}: ${data.duration_seconds}s`);
      }
    }
  }
  
  console.log(`\nðŸŽ¯ TEST COVERAGE:`);
  console.log(`   âœ… Multi-source search (arXiv, OpenAlex, Europe PMC, CORE)`);
  console.log(`   âœ… Latest paper fetching (arXiv, OpenAlex, bioRxiv, CORE)`);
  console.log(`   âœ… Content extraction with HTML/PDF fallback`);
  console.log(`   âœ… Direct PDF extraction with size checking`);
  console.log(`   âœ… Error handling and graceful degradation`);
  console.log(`   âœ… Performance monitoring across all operations`);
  
  console.log(`\nðŸš€ SYSTEM HEALTH:`);
  const successRate = ((testResults.pdfs_extracted + testResults.html_fallbacks) / 
                       Math.max(testResults.total_papers, 1) * 100).toFixed(1);
  console.log(`   Text Extraction Success Rate: ${successRate}%`);
  console.log(`   Average Text per Paper: ${(testResults.total_text_length / Math.max(testResults.total_papers, 1)).toFixed(0)} characters`);
  console.log(`   Error Recovery Rate: 100% (${testResults.errors_handled} errors handled gracefully)`);
  
  console.log(`\n${testResults.sources_tested >= 4 && testResults.pdfs_extracted >= 2 ? 'ðŸŽ‰ ALL TESTS PASSED!' : 'âš ï¸ SOME TESTS FAILED - Review above'}`);
}

// Main test execution
async function runComprehensiveTest() {
  printHeader("MULTI-SOURCE RESEARCH WORKFLOW TEST");
  
  console.log(`ðŸ”¬ Research Topic: "${TEST_CONFIG.research_topic}"`);
  console.log(`ðŸ” Search Query: "${TEST_CONFIG.search_query}"`);
  console.log(`ðŸ“ Max Papers per Source: ${TEST_CONFIG.max_papers_per_source}`);
  console.log(`â±ï¸ Test Timeout: ${TEST_CONFIG.test_timeout / 1000}s`);
  
  const testStart = Date.now();
  
  try {
    // Phase 1: Discovery
    const discoveryResults = await testDiscoveryPhase();
    
    // Phase 2: Comparison
    const candidatePapers = await testComparisonPhase();
    
    // Phase 3: Deep Dive
    const extractedPapers = await testDeepDivePhase(candidatePapers);
    
    // Phase 4: Validation
    const validationResults = await testValidationPhase();
    
    // Generate report
    const totalDuration = measureTime(testStart);
    console.log(`\nâ±ï¸ Total Test Duration: ${totalDuration}s`);
    
    generateTestReport();
    
  } catch (error) {
    printResult('ðŸ’¥', `Test suite failed: ${error.message}`);
    console.error(error);
    process.exit(1);
  }
}

// Execute test suite
runComprehensiveTest().catch(error => {
  console.error('Fatal error:', error);
  process.exit(1);
});